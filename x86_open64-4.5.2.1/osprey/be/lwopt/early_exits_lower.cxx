// ====================================================================
//
// Copyright (C) 2010, Hewlett-Packard Development Company, L.P.
// All Rights Reserved.
//
// This program is free software; you can redistribute it and/or modify
// it under the terms of version 2 of the GNU General Public License as
// published by the Free Software Foundation.
//
// This program is distributed in the hope that it would be useful, but
// WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
//
// Further, this software is distributed without any warranty that it
// is free of the rightful claim of any third person regarding
// infringement  or the like.  Any license provided herein, whether
// implied or otherwise, applies only to this software file.  Patent
// licenses, if any, provided herein do not apply to combinations of
// this program with other software, or any other product whatsoever.
//
// You should have received a copy of the GNU General Public License
// along with this program; if not, write the Free Software Foundation,
// Inc., 59 Temple Place - Suite 330, Boston MA 02111-1307, USA.
//
// ====================================================================
// Module: early_exits_lower.cxx
//
// Description:
// 'LWOPT_LOWER::lower()' translates the new intrinsics generated by the code
// in early_exits.cxx to equivalent known constructs. Currently, there are
// four such intrinsics: INTRN_SWITCH_RETURN, INTRN_VSWITCH_RETURN, 
// FIRST_TRUE_INDEX and VEC_FIRST_TRUE_INDEX. These intrinsics are translated
// by lower_Switch_Return(), lower_VSwitch_Return(), lower_Switch_Branch()
// and lower_VSwitch_Branch(), respectively. Detailed comments are described
// above each of the four functions.
// 
// ====================================================================

#include "early_exits_lower.h"
#include "wssa_update.h"



const O64_ComponentDescriptor LWOPT_LOWER::ComponentDescriptor =
{
    O64_COMPONENT_DESC("Early-Exits Lower", "EELOWER", OptionDescriptors)
};



const O64_OptionDescriptor LWOPT_LOWER::OptionDescriptors[] =
{
    O64_OPTION_DESC(LWOPT_lower_skip_BB_before, "skip the basic blocks before",
                "skip_bb_b", "sbb", OVK_UINT32, OV_INTERNAL, false, 0, 0, UINT32_MAX),
    O64_OPTION_DESC(LWOPT_lower_skip_BB_after, "skip the basic blocks after",
                "skip_bb_a", "sba", OVK_UINT32, OV_INTERNAL, false, UINT32_MAX, 0, UINT32_MAX),
    O64_OPTION_DESC(LWOPT_lower_last, "end marker", 0, 0, OVK_INVALID, OV_INTERNAL, false, 0, 0, 0)
};




static O64_ComponentInitializer lwopt_lower_init(
    COMPONENT_lwopt_earlyexits_lower, &LWOPT_LOWER::ComponentDescriptor);
    



void 
LWOPT_Lower()
{
  LWOPT_LOWER lwopt_lower;
}



LWOPT_LOWER::LWOPT_LOWER()
    :O64_Component(COMPONENT_lwopt_earlyexits_lower)
{
    if (!_enable) return;

    CurrentWN_   = _Driver->GetCurrentWN();
    CurrentWCFG_ = _Driver->GetCurrentWCFG();
    CurrentWSSA_ = _Driver->GetCurrentWSSA();
    if (_TraceKind >= TRACE_maximal) {
      fprintf(TFile, "\n\n%s: before LWOPT_LOWER\n", get_PU_name());
      dump_tree_ssa(CurrentWN_);
    }

    MEM_POOL_Initialize(&mem_pool,"EARLY_EXIT_LOWER POOL",FALSE);
    SIMD_reg_width = 16;
    WSSA_UPDATER updater(CurrentWN_, CurrentWCFG_, CurrentWSSA_);
    updater.Enable_update_cfg();
    wssa_updater = &updater;

    return_info = Get_Return_Info(TY_ret_type(Ty_Table[PU_prototype (Get_Current_PU())]), Complex_Not_Simulated);
    ret_preg = RETURN_INFO_preg(return_info,0);
    ret_type = RETURN_INFO_mtype(return_info,0);
    ret_st   = MTYPE_To_PREG(ret_type);
    temp_stack_mem = create_symbol();
    mtype = Is_Target_64bit() ? MTYPE_U8 : MTYPE_U4;
    
    lower();
    _Driver->InvalidateWCFG();
    if (_TraceKind >= TRACE_maximal) {
      fprintf(TFile, "%s: after LWOPT_LOWER\n", get_PU_name());
      dump_tree_ssa(CurrentWN_);
    }
}




void
LWOPT_LOWER::lower()
{ 
  // for each basic block in cfg
  // for each stmt in cfg
  // if (switchreturn intrinsic)
  // lower_switchreturn();

  list<WN*> Switch_Returns;
  list<WN*> VSwitch_Returns;
  list<WN*> Switch_Branches;
  list<WN*> VSwitch_Branches;

  if (_TraceKind >= TRACE_maximal) {
    char * PU_name = ST_name(&St_Table[PU_Info_proc_sym(Current_PU_Info)]);
    fprintf(TFile, "LWOPT_LOWER::lower: %s\n", PU_name);
  }

  WN_CFG::dfs_fwd_iterator bbiter = CurrentWCFG_->Dfs_fwd_begin(); 
  for (; bbiter != CurrentWCFG_->Dfs_fwd_end(); ++bbiter) { 
    WN_CFG::BB_NODE *bb = &(*bbiter);
    if (bb == CurrentWCFG_->Get_dummy_entry()) continue;

    collect_intrinsics(bb, 
		       Switch_Returns, VSwitch_Returns, 
		       Switch_Branches, VSwitch_Branches);
  } 

  lower_intrinsics(Switch_Returns,  INTRN_SWITCH_RETURN);
  lower_intrinsics(VSwitch_Returns, INTRN_VSWITCH_RETURN);
  lower_intrinsics(Switch_Branches, INTRN_SWITCH_BRANCH);
  lower_intrinsics(VSwitch_Branches,INTRN_VSWITCH_BRANCH);
}





// --------------------------------------------------------------------
// collect the intrinsics to lower
// --------------------------------------------------------------------

void
LWOPT_LOWER::collect_intrinsics(WN_CFG::BB_NODE* bb,
				list<WN*>& Switch_Returns, 
				list<WN*>& VSwitch_Returns, 
				list<WN*>& Switch_Branches, 
				list<WN*>& VSwitch_Branches)
{ 
  WN_CFG::BB_NODE::stmt_iterator stmt_it = bb->Stmt_begin();
  for (; stmt_it != bb->Stmt_end(); ++stmt_it) { 
    WN *stmt = &(*stmt_it);
    if (WN_is_SwitchReturn(stmt)){
      if (_TraceKind >= TRACE_maximal)
	fprintf (TFile, "Collecting scalar SwitchReturn...\n");
      Switch_Returns.push_back(stmt);
    }
    if (WN_is_VSwitchReturn(stmt)){
      if (_TraceKind >= TRACE_maximal)
	fprintf (TFile, "Collecting vector SwitchReturn...\n");
      VSwitch_Returns.push_back(stmt);
    }
    if (WN_is_SwitchBranch(stmt)){
      if (_TraceKind >= TRACE_maximal)
	fprintf (TFile, "Collecting scalar SwitchBranch...\n");
      Switch_Branches.push_back(stmt);
    }
    if (WN_is_VSwitchBranch(stmt)){
      if (_TraceKind >= TRACE_maximal)
	fprintf (TFile, "Collecting vector SwitchBranch...\n");
      VSwitch_Branches.push_back(stmt);
    }

    // possible bug: blindly considers the destination of all statements
    //               with compares as comparison results.
    if (WN_has_CMP(stmt) && WN_has_ver(stmt)) 
      _conditionals.insert(CurrentWSSA_->Get_wn_ver(stmt));
  } 
}





void
LWOPT_LOWER::lower_intrinsics(list<WN*>& intrinsics, INTRINSIC intr)
{ 
  std::list<WN*>::iterator wn_iter = intrinsics.begin();
  for (; wn_iter != intrinsics.end(); wn_iter++)
    { 
      WN *inst = *wn_iter;
      block = CurrentWCFG_->Get_parent_block(inst);
      switch(intr)
	{
	case INTRN_SWITCH_RETURN:  lower_Switch_Return(inst); break;
	case INTRN_SWITCH_BRANCH:  lower_Switch_Branch(inst); break;
	case INTRN_VSWITCH_RETURN: lower_VSwitch_Return(inst);break;
	case INTRN_VSWITCH_BRANCH: lower_VSwitch_Branch(inst);break;
	default: Is_True(0, ("LWOPT_LOWER::lower_intrinsics: unimplemented(%d)", intr));
	}
      wssa_updater->Delete_stmt(block, inst);  // laijx
    }
  intrinsics.clear();
}






// --------------------------------------------------------------------
// scalar SwitchReturn:
// --------------------------------------------------------------------

// This method will currently lower a switch-return intrinsic into 
// a chain of if then else conditions.
//
//  SwitchReturn c1, e1, c2, e2, ..cn, en
//
// will be lowered to 
// 
//    if (!c1) goto L1; 
//    return e1;
//    L1: 
//    if (!c2) goto L2;  
//    return e2;
//    L2: 
//    if (!c3) goto L3;  
//    return e3;
//    L3: 
//    default_label:

void
LWOPT_LOWER::lower_Switch_Return(WN *wn)
{ 
  UINT32 pos = 0;
  UINT32 kids =  WN_kid_count(wn);
  FmtAssert(kids%2==0, ("switch return op must have even number of kids"));

  while (pos < kids)
  { 
    WN *cond    = wssa_updater->Copy_tree(WN_kid0(WN_kid(wn,pos++)));
    WN *ret_val = wssa_updater->Copy_tree(WN_kid0(WN_kid(wn,pos++)));

    // create a new label L.
    LABEL_IDX lbl;
    New_LABEL(CURRENT_SYMTAB, lbl);
    WN* label_wn = WN_CreateLabel(lbl, 0, NULL);
    EE_LOWER_insert_before(label_wn, wn);

    // create a new branch
    WN *falsebr = WN_CreateFalsebr(WN_label_number(label_wn), cond);
    EE_LOWER_insert_before(falsebr, label_wn);

    // add 'return'
    TYPE_ID   ret_desc = WN_rtype(ret_val);
    ST*       preg_st  = MTYPE_To_PREG(ret_type);
    WN*       ret_stmt = WN_CreateStid (OPCODE_make_op(OPR_STID, MTYPE_V, ret_desc), ret_preg, preg_st, ret_desc,ret_val);
    EE_LOWER_insert_before(ret_stmt, label_wn);

    WN *ret = WN_CreateReturn();
    EE_LOWER_insert_before(ret, label_wn);
  } 
} 






// --------------------------------------------------------------------
// vector SwitchReturn:
// --------------------------------------------------------------------
//  VSwitchReturn( VC, VR, num_valid_elements )
//
// will be lowered to 
// 
//  mask = movemask (VC)
//  mask = mask & 0xfff.. (only if num_valid_elements != vector length)
//  if (!mask) goto 'the_next_statement'
//  index = ctz(mask)
//  shift right VR
//  store VR to 'mem'
//  load an element from 'mem'
//  return the element
//  the_next_statement:

void
LWOPT_LOWER::lower_VSwitch_Return(WN *vswitch_ret)
{ 
  WN* vcond    = WN_kid0(WN_kid0(vswitch_ret));
  WN* vret_val = WN_kid0(WN_kid1(vswitch_ret));
  WN* num_ele  = WN_kid0(WN_kid2(vswitch_ret));

  TYPE_ID mask_type = get_mask_type(WN_rtype(vcond));
  int vector_length = SIMD_reg_width / MTYPE_byte_size(mask_type);
  int valid_lanes   = WN_const_val(num_ele);

  // Since there are no 16-bit movemask instructions, we use 8-bit 
  // movemask instruction instead. Thus, the 'index' should be 
  // divided by 2 when processing 16-bit operands.
  INT32 num_bits = MTYPE_bit_size(get_scalar_type(WN_rtype(vcond)));
  bool is_16bit_element = num_bits == 16 ? true : false;
  if (is_16bit_element) valid_lanes *= 2;

  WN* movemask = gen_movemask(vswitch_ret);
  if (vector_length != valid_lanes) 
    movemask = gen_mask(movemask, valid_lanes, vswitch_ret);

  WN* label = gen_if(movemask, vswitch_ret);
  WN* index = gen_ctz(movemask, label);
  if (is_16bit_element) index = gen_lshr1(index, label);
  gen_stid_to_temp_mem(vret_val, index, label);
  gen_return(index, label, MTYPE_byte_size(mask_type), is_conditional(vret_val));
}






// --------------------------------------------------------------------
// scalar SwitchBranch:
// --------------------------------------------------------------------
//  COMPGOTO
//    kid0 FIRST_TRUE_INDEX(t1, t2, t3)
//    Kid1
//      GOTO L1;
//      GOTO L2;
//      GOTO L3;
//    kid2  GOTO L4;
//  END COMPGOTO
//
// will be lowered to 
// 
//    if (t1) goto L1; 
//    if (t2) goto L2;  
//    if (t3) goto L3;  
//    goto L4;

void
LWOPT_LOWER::lower_Switch_Branch(WN *s_br)
{ 
  WN* intrn = WN_kid0(s_br);
  WN* blk = WN_kid1(s_br);
  WN* goto_stmt = WN_first(blk);
  UINT32 pos = 0;
  while (goto_stmt)
  { 
    // create a new branch each label of the COMPGOTO
    WN* cond = WN_COPY_Tree(WN_kid(intrn, pos++));
    WN *truebr = WN_CreateTruebr(WN_label_number(goto_stmt), cond);
    EE_LOWER_insert_before(truebr, s_br);
    goto_stmt = WN_next(goto_stmt);
  } 

  // insert the default GOTO
  if (WN_kid_count(s_br) > 2) {
    WN* dflt_goto = WN_CreateGoto((ST_IDX)NULL, WN_label_number(WN_kid2(s_br)));
    EE_LOWER_insert_before(dflt_goto, s_br);
  }
}






// --------------------------------------------------------------------
// vector SwitchBranch:
// --------------------------------------------------------------------
//  COMPGOTO
//    kid0 VEC_FIRST_TRUE_INDEX(VC)
//    Kid1
//      GOTO L1;
//      GOTO L2;
//      GOTO L3;
//    kid2  GOTO L4;
//  END COMPGOTO
//
// will be lowered to 
// 
//  mask = movemask (VC)
//  mask = mask & 0xfff.. (only if num_valid_elements != vector length)
//  if (!mask) goto L4
//  index = ctz(mask)
//  COMPGOTO
//    kid0 index
//    Kid1
//      GOTO L1;
//      GOTO L2;
//      GOTO L3;
//    kid2  GOTO L4;
//  END COMPGOTO
//  L4:

void
LWOPT_LOWER::lower_VSwitch_Branch(WN *vswitch_br)
{ 
  WN* vcond       = WN_kid0(WN_kid0(WN_kid0(vswitch_br)));
  int valid_lanes = WN_num_entries(vswitch_br);

  TYPE_ID mask_type = get_mask_type(WN_rtype(vcond));
  int vector_length = SIMD_reg_width / MTYPE_byte_size(mask_type);

  // Since there are no 16-bit movemask instructions, we use 8-bit 
  // movemask instruction instead. Thus, the 'index' should be 
  // divided by 2 when processing 16-bit operands.
  INT32 num_bits = MTYPE_bit_size(get_scalar_type(WN_rtype(vcond)));
  bool is_16bit_element = num_bits == 16 ? true : false;
  if (is_16bit_element) valid_lanes *= 2;

  WN* movemask = gen_movemask(vswitch_br);
  if (vector_length != valid_lanes) 
    movemask = gen_mask(movemask, valid_lanes, vswitch_br);

  gen_if(movemask, vswitch_br);
  WN* index = gen_ctz(movemask, vswitch_br);
  if (is_16bit_element) index = gen_lshr1(index, vswitch_br);
  gen_COMPGOTO(index, vswitch_br);
}





// --------------------------------------------------------------------
// common routines
// --------------------------------------------------------------------
WN*
LWOPT_LOWER::gen_movemask(WN *vswitch_ret)
{ 
  // is VectorSwitchReturn?
  bool is_VSR = WN_is_VSwitchReturn(vswitch_ret);

  WN*      vcond       = is_VSR ? WN_kid0(WN_kid0(vswitch_ret))
                                : WN_kid0(WN_kid0(WN_kid0(vswitch_ret)));
  TYPE_ID  vector_type = WN_rtype(vcond);
  PREG_NUM mask_preg   = Create_Preg(mtype, "_lower_");

  WN* kid[1]; TY_IDX typ[1];
  kid[0]    = make_LDID(vcond, CurrentWSSA_);
  typ[0]    = MTYPE_To_TY(vector_type);

  int nbits_scalar = MTYPE_bit_size(get_scalar_type(vector_type));
  INTRINSIC intrn;
  switch(nbits_scalar)
    {
    case 8:  intrn = INTRN_PMOVMSKB128; break;
    // use 8-bit movemask instead in the lack of 16-bit movemask
    case 16: intrn = INTRN_PMOVMSKB128; break;
    case 32: intrn = INTRN_MOVMSKPS; break;
    case 64: intrn = INTRN_MOVMSKPD; break;
    default: Is_True(0, ("LWOPT_LOWER::gen_movemask: no movemask for size(%d)", nbits_scalar));
    }
  WN* movemask = gen_an_intrinsic(intrn, mask_preg, 
				  MTYPE_To_PREG(mtype), kid, 1, typ);
  EE_LOWER_insert_before(movemask, vswitch_ret);
  return movemask;
}





// generates 'mask(bitwise and, &)' operation to clear bits for 
// not-valid vector lanes for partial vector lanes
WN*
LWOPT_LOWER::gen_mask(WN *movemask, int valid_lanes, WN *vswitch_ret)
{ 
  WN* mask = WN_Intconst(mtype, make_mask(valid_lanes));
  WN* bits = make_LDID(movemask, CurrentWSSA_);
  WN* band = WN_Create(OPR_BAND, mtype, MTYPE_V, 2);

  WN_kid0(band) = bits;
  WN_kid1(band) = mask;

  PREG_NUM mask_preg = Create_Preg(mtype, "_lower_");
  WN* band_stid = WN_StidIntoPreg(mtype, mask_preg, 
				 MTYPE_To_PREG(mtype), band);
  EE_LOWER_insert_before(band_stid, vswitch_ret);

  return band_stid;
}





// - generates a 'true branch' to the label. This true branch bypasses 
//   the 'return' statement to the next statements 
// - returns the 'label' WN before which 'return' is inserted
WN*
LWOPT_LOWER::gen_if(WN *movemask, WN *vswitch_ret)
{ 
  // is VectorSwitchReturn?
  bool is_VSR = WN_is_VSwitchReturn(vswitch_ret);

  // create a new label L.
  LABEL_IDX lbl;
  New_LABEL(CURRENT_SYMTAB, lbl);
  WN* label = WN_CreateLabel(lbl, 0, NULL);

  // create a condition
  WN* mask  = make_LDID(movemask, CurrentWSSA_);

  // create a true branch
  WN* wn = is_VSR ? label : WN_kid2(vswitch_ret);
  WN *truebr = WN_CreateFalsebr(WN_label_number(wn), mask);
  EE_LOWER_insert_before(truebr, vswitch_ret);
  if (is_VSR) EE_LOWER_insert_before(label, vswitch_ret);
  return is_VSR ? label : vswitch_ret;
}





WN*
LWOPT_LOWER::gen_ctz(WN* mask, WN* label)
{ 
  PREG_NUM index_preg = Create_Preg(mtype, "_lower_");

  WN* kid[1]; TY_IDX typ[1];
  kid[0]    = make_LDID(mask, CurrentWSSA_);
  typ[0]    = MTYPE_To_TY(mtype);

  WN* ctz   = gen_an_intrinsic(INTRN_CTZ, index_preg, 
			       MTYPE_To_PREG(mtype), kid, 1, typ);
  EE_LOWER_insert_before(ctz, label);
  return ctz;
}





WN*
LWOPT_LOWER::gen_lshr1(WN* index, WN* label)
{ 
  WN* kid = make_LDID(index, CurrentWSSA_);
  WN* one = WN_Intconst(mtype, 1);
  WN* shr = WN_Lshr(mtype, kid, one);

  PREG_NUM shr_preg = Create_Preg(mtype, "_lower_");
  WN*      shr_stid = WN_StidIntoPreg(mtype, shr_preg, 
				      MTYPE_To_PREG(mtype), shr);
  EE_LOWER_insert_before(shr_stid, label);

  return shr_stid;
}





ST* 
LWOPT_LOWER::create_symbol()
{
  ST* st = New_ST(CURRENT_SYMTAB);
  ST_Init (st,
	   Save_Str("$early_exits_buffer"),
	   CLASS_VAR,
	   SCLASS_AUTO,
	   EXPORT_LOCAL,
	   Be_Type_Tbl(MTYPE_V16I1));
  Set_ST_is_temp_var(st);
  return st;
}





void
LWOPT_LOWER::gen_stid_to_temp_mem(WN* vret_val, WN* index, WN *label)
{ 
  TYPE_ID vector_type = WN_rtype(vret_val);
  TY_IDX  ty          = WN_ty(vret_val);
  ST*     lower_temp  = temp_stack_mem;
  WN*     vret        = make_LDID(vret_val, CurrentWSSA_);

  WN* v_stid = WN_CreateStid (OPR_STID, MTYPE_V, MTYPE_V16I1, 0, 
			      lower_temp, ty, vret);
  EE_LOWER_insert_before(v_stid, label);
}





void
LWOPT_LOWER::gen_return(WN* index, WN *label, int byte_size, bool cond)
{ 
  TY_IDX addr_ty = Make_Pointer_Type(ST_type(temp_stack_mem));
  TYPE_ID ptr_type = TY_mtype(addr_ty);
  WN* lda  = WN_Lda(ptr_type, 0, temp_stack_mem);
  WN* ori_index = make_LDID(index, CurrentWSSA_);
  WN* typesize = WN_CreateIntconst(OPR_INTCONST, MTYPE_I4, MTYPE_V, byte_size);

  WN* new_index = WN_Mpy(MTYPE_I4, ori_index, typesize);
  WN* addr = WN_Add(ptr_type, new_index, lda);

  TY_IDX ty = MTYPE_To_TY(ret_type);
  WN* iload = WN_CreateIload (OPR_ILOAD, ret_type, ret_type,
			      0, ty, addr_ty, addr);

  WN_OFFSET preg = cond ? Create_Preg(ret_type, "_lower_") : ret_preg;
  WN* ret_stid = WN_CreateStid(OPR_STID, MTYPE_V, ret_type, preg, 
			       ret_st, ty, iload);
  EE_LOWER_insert_before(ret_stid, label);

  // shift right for conditional variable
  if (cond) gen_cvted_cond(ret_stid, label);

  WN *ret = WN_CreateReturn();
  EE_LOWER_insert_before(ret, label);
}





  
// create a 'shift right' statement that converts -1's to 1's
// in the scalar register.
void LWOPT_LOWER::gen_cvted_cond(WN* elem, WN *label) 
{
  // create SHR
  int nbits    = MTYPE_bit_size(ret_type);
  WN* shr      = WN_Create(OPR_LSHR, ret_type, MTYPE_V, 2);
  WN_kid0(shr) = make_LDID(elem, CurrentWSSA_);
  WN_kid1(shr) = WN_CreateIntconst(OPR_INTCONST, MTYPE_I4, MTYPE_V, nbits-1);

  // create STID
  WN* cvted_cond = WN_StidIntoPreg(ret_type, ret_preg, ret_st, shr);
  EE_LOWER_insert_before(cvted_cond, label);
}





void
LWOPT_LOWER::gen_COMPGOTO(WN* index, WN *vswitch_br)
{ 
  WN* new_vswitch_br = WN_COPY_Tree(vswitch_br);
  WN_DELETE_Tree(WN_kid0(new_vswitch_br));
  WN_kid0(new_vswitch_br) = make_LDID(index, CurrentWSSA_);
  EE_LOWER_insert_before(new_vswitch_br, vswitch_br);
}
 




  
// insert wn before 'before'
void 
LWOPT_LOWER::EE_LOWER_insert_before(WN* wn, WN* before) 
{
  wssa_updater->Insert_before(block, before, wn);

  set_map_id(wn);
}
 




  
// insert wn after 'after'
void 
LWOPT_LOWER::EE_LOWER_insert_after(WN* wn, WN* after) 
{
  wssa_updater->Insert_after(block, after, wn);

  set_map_id(wn);
}





  
// set map_id for wn
void 
LWOPT_LOWER::set_map_id(WN* wn) 
{
  if (!wn) return;
  WN_MAP_Set_ID(Current_Map_Tab, wn);

  for (int i=0; i<WN_kid_count(wn); i++)
    set_map_id(WN_kid(wn, i));
}




// create an intrinsic 
WN* 
LWOPT_LOWER::gen_an_intrinsic(INTRINSIC intrinsic, 
			      WN_OFFSET offset, // offset or preg_num of dst
			      ST* dst_st, WN** kid, int num_kids, TY_IDX typ[])
{
  for (int i=0; i<num_kids; i++)
    kid[i] = WN_CreateParm(WN_rtype(kid[i]), kid[i], typ[i], WN_PARM_BY_VALUE);

  TYPE_ID rtype = TY_mtype(ST_type(dst_st));
  WN* wn = WN_Create_Intrinsic(OPR_INTRINSIC_OP, rtype, 
			       MTYPE_V, intrinsic, num_kids, kid);
  // new STID into the scalar
  WN* new_stid = WN_StidIntoPreg(rtype, offset, dst_st, wn);

  return new_stid;
}
 




  
// true if wn is an LDID for conditional variable
bool 
LWOPT_LOWER::is_conditional(WN* wn) 
{
  if (!WN_has_ver(wn)) return false;

  VER_IDX vidx = CurrentWSSA_->Get_wn_ver(wn);
  if (_conditionals.find(vidx) == _conditionals.end()) return false;

  return true;
}

